{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fadimrb26/thesis/blob/main/IsingRun.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxjnsCs9ot-Y"
      },
      "source": [
        "## 1) Install the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZXo5akM12xIL",
        "outputId": "d4cac1a3-f5e6-4597-e035-edc7d606ad36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  ngspice-doc\n",
            "The following NEW packages will be installed:\n",
            "  ngspice\n",
            "0 upgraded, 1 newly installed, 0 to remove and 34 not upgraded.\n",
            "Need to get 2,352 kB of archives.\n",
            "After this operation, 7,972 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 ngspice amd64 36+ds-1ubuntu0.1 [2,352 kB]\n",
            "Fetched 2,352 kB in 1s (1,933 kB/s)\n",
            "Selecting previously unselected package ngspice.\n",
            "(Reading database ... 126332 files and directories currently installed.)\n",
            "Preparing to unpack .../ngspice_36+ds-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking ngspice (36+ds-1ubuntu0.1) ...\n",
            "Setting up ngspice (36+ds-1ubuntu0.1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (3.4.2)\n",
            "Collecting minorminer\n",
            "  Downloading minorminer-0.2.18-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (19 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Collecting dwave-networkx>=0.8.13 (from minorminer)\n",
            "  Downloading dwave_networkx-0.8.17-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting fasteners>=0.15 (from minorminer)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting homebase>=1.0.1 (from minorminer)\n",
            "  Downloading homebase-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: scipy>=1.7.3 in /usr/local/lib/python3.11/dist-packages (from minorminer) (1.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Collecting dimod>=0.10.8 (from dwave-networkx>=0.8.13->minorminer)\n",
            "  Downloading dimod-0.12.20-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading minorminer-0.2.18-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dwave_networkx-0.8.17-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.7/103.7 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading homebase-1.0.1-py2.py3-none-any.whl (11 kB)\n",
            "Downloading dimod-0.12.20-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: homebase, fasteners, dimod, dwave-networkx, minorminer\n",
            "Successfully installed dimod-0.12.20 dwave-networkx-0.8.17 fasteners-0.19 homebase-1.0.1 minorminer-0.2.18\n"
          ]
        }
      ],
      "source": [
        "!apt-get install -y ngspice\n",
        "!pip install networkx minorminer tqdm numpy pandas seaborn matplotlib\n",
        "\n",
        "from IPython.display import clear_output\n",
        "from itertools import combinations\n",
        "from tqdm import tqdm\n",
        "from collections import defaultdict\n",
        "import os\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import minorminer\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from google.colab import files"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKllj5Dlo4Oi"
      },
      "source": [
        "# 2) Generate SPICE Netlists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnupEhJ03A7N"
      },
      "outputs": [],
      "source": [
        "def generate_spice_netlist(G, embedding, graph='fc'):\n",
        "    spice_code = [\n",
        "        \"* CMOS Capacitive-Coupled Ising Machine\",\n",
        "        \".model PMOS PMOS (VTO=-0.4 KP=100u)\",\n",
        "        \".model NMOS NMOS (VTO=0.4 KP=200u)\",\n",
        "        \".model SWMODEL SW(Ron=1 Roff=1G Vt=0.5 Vh=0)\\n\",\n",
        "        \"* Define the latch subcircuit\",\n",
        "        \".SUBCKT LATCH Q Qb VDD GND PARAMS: VQ_init=0 VQb_init=0\",\n",
        "        \"M1 Q  Qb VDD VDD PMOS W=360n L=45n\",\n",
        "        \"M2 Q  Qb GND GND NMOS W=180n L=45n\",\n",
        "        \"M3 Qb Q VDD VDD PMOS W=360n L=45n\",\n",
        "        \"M4 Qb Q GND GND NMOS W=180n L=45n\",\n",
        "        \"C1 Q  GND 100f\",\n",
        "        \"C2 Qb GND 100f\",\n",
        "        \".IC V(Q)={VQ_init} V(Qb)={VQb_init}\",\n",
        "        \".ENDS LATCH\\n\",\n",
        "        \"* Power supply\",\n",
        "        \"Vdd VDD 0 1.1V\\n\"\n",
        "    ]\n",
        "\n",
        "    logical_to_spice = {node: f\"Q{node}\" for node in G.nodes()}\n",
        "\n",
        "    if graph == 'fc':\n",
        "        for node in G.nodes():\n",
        "            spice_code.append(f\"X{node} {logical_to_spice[node]} {logical_to_spice[node]}b VDD 0 LATCH PARAMS: VQ_init=0V VQb_init=0V\")\n",
        "    elif graph == 'lattice':\n",
        "        for node, chain in embedding.items():\n",
        "            for qubit in chain:\n",
        "                spice_code.append(f\"X{qubit[0]}{qubit[1]} {logical_to_spice[node]} {logical_to_spice[node]}b VDD 0 LATCH PARAMS: VQ_init=0V VQb_init=0V\")\n",
        "\n",
        "    spice_code.append(\"\\n\")\n",
        "    switch_idx = 0\n",
        "    for (u, v) in G.edges():\n",
        "        spice_code.append(f\"* Connection between latch {u} and latch {v}\")\n",
        "        spice_code.append(f\"S{switch_idx}_{switch_idx * 4} {logical_to_spice[u]} N{switch_idx * 4} FLY_CTRL{switch_idx} 0 SWMODEL\")\n",
        "        spice_code.append(f\"S{switch_idx}_{switch_idx * 4 + 1} {logical_to_spice[v]} N{switch_idx * 4 + 1} FLY_CTRL{switch_idx} 0 SWMODEL\")\n",
        "        spice_code.append(f\"S{switch_idx}_{switch_idx * 4 + 2} {logical_to_spice[u]}b N{switch_idx * 4 + 2} FLY_CTRL{switch_idx} 0 SWMODEL\")\n",
        "        spice_code.append(f\"S{switch_idx}_{switch_idx * 4 + 3} {logical_to_spice[v]}b N{switch_idx * 4 + 3} FLY_CTRL{switch_idx} 0 SWMODEL\")\n",
        "\n",
        "        spice_code.append(\"\\n\")\n",
        "\n",
        "        spice_code.append(f\"S{switch_idx}i_{switch_idx * 4} {logical_to_spice[u]}b N{switch_idx * 4} NFLY_CTRL{switch_idx} 0 SWMODEL\")\n",
        "        spice_code.append(f\"S{switch_idx}i_{switch_idx * 4 + 1} {logical_to_spice[v]} N{switch_idx * 4 + 1} NFLY_CTRL{switch_idx} 0 SWMODEL\")\n",
        "        spice_code.append(f\"S{switch_idx}i_{switch_idx * 4 + 2} {logical_to_spice[u]} N{switch_idx * 4 + 2} NFLY_CTRL{switch_idx} 0 SWMODEL\")\n",
        "        spice_code.append(f\"S{switch_idx}i_{switch_idx * 4 + 3} {logical_to_spice[v]}b N{switch_idx * 4 + 3} NFLY_CTRL{switch_idx} 0 SWMODEL\")\n",
        "\n",
        "        spice_code.append(\"\\n\")\n",
        "\n",
        "        spice_code.append(f\"C_fly_{switch_idx * 2} N{switch_idx * 4} N{switch_idx * 4 + 1} {cap_values_femto}f\")\n",
        "        spice_code.append(f\"C_fly_{switch_idx * 2 + 1} N{switch_idx * 4 + 2} N{switch_idx * 4 + 3} {cap_values_femto}f\")\n",
        "        spice_code.append(\"\\n\")\n",
        "\n",
        "        switch_idx += 1\n",
        "\n",
        "    for i in range(switch_idx):\n",
        "        spice_code.append(f\"Vfly_ctrl{i} FLY_CTRL{i} 0 DC 0\")\n",
        "        spice_code.append(f\"Vnfly_ctrl{i} NFLY_CTRL{i} 0 DC 1.1\")\n",
        "        spice_code.append(\"\\n\")\n",
        "\n",
        "    spice_code.append(\".tran 0.01n 60n\")\n",
        "    q_values = \" \".join([f\"V({logical_to_spice[node]})\" for node in G.nodes()])\n",
        "    spice_code.append(\".control\")\n",
        "    spice_code.append(\"run\")\n",
        "    spice_code.append(f\"wrdata Automated{graph}Ising.csv {q_values}\")\n",
        "    spice_code.append(\".endc\")\n",
        "    spice_code.append(\".end\")\n",
        "\n",
        "    return \"\\n\".join(spice_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HuWPbO-zpBnD"
      },
      "source": [
        "# 3) Find the minimum lattice size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jo2K9dvZ29k8"
      },
      "outputs": [],
      "source": [
        "# Function Definitions (unchanged except for file handling)\n",
        "def find_minimum_lattice_size(G):\n",
        "    lattice_size = 2\n",
        "    while lattice_size < 10:\n",
        "        square_lattice = nx.grid_2d_graph(lattice_size, lattice_size)\n",
        "        if len(G.edges()) == 0:\n",
        "            embedding = {node: [(np.random.randint(0, lattice_size), np.random.randint(0, lattice_size))] for node in G.nodes()}\n",
        "        else:\n",
        "            embedding = minorminer.find_embedding(G.edges(), square_lattice.edges())\n",
        "\n",
        "        if embedding:\n",
        "            return lattice_size, square_lattice, embedding\n",
        "        lattice_size += 1\n",
        "    return None, None, None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2KbtUJApNbn"
      },
      "source": [
        "# 4) Run NGSPICE and compute Hamiltonian and Converging Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iftB0IaZ3EvA"
      },
      "outputs": [],
      "source": [
        "def run_ngspice_colab(netlist_path):\n",
        "    if not os.path.exists(netlist_path):\n",
        "        print(\"Path doesn't exist...\")\n",
        "        return False\n",
        "    exit_code = os.system(f\"ngspice -b {netlist_path} > /dev/null 2>&1\")\n",
        "    return (exit_code % 256) == 0\n",
        "\n",
        "def solve_ising_problem(G):\n",
        "    cut_value, partition = nx.algorithms.approximation.maxcut.one_exchange(G)\n",
        "    ising_spins = {node: -1 if node in partition[0] else +1 for node in G.nodes()}\n",
        "    return -sum(ising_spins[i] * ising_spins[j] for (i, j) in G.edges())\n",
        "\n",
        "import pandas as pd\n",
        "def compute_hamiltonian(solution, edges):\n",
        "    try:\n",
        "        # Read the CSV file with alternating time and voltage columns\n",
        "        df = pd.read_csv(solution, sep='\\s+', header=None, skipinitialspace=True)\n",
        "\n",
        "        # Separate time and voltage columns\n",
        "        time_col = df.iloc[:, ::2]  # Time columns (0, 2, 4,...)\n",
        "        voltage_cols = df.iloc[:, 1::2]  # Voltage columns (1, 3, 5,...)\n",
        "\n",
        "        # Find first time where any voltage exceeds 0 or 1.1\n",
        "        threshold_mask = (voltage_cols < 0) | (voltage_cols > 1.1)\n",
        "        first_exceed_index = threshold_mask.any(axis=1).idxmax()\n",
        "        first_exceed_time = time_col.iloc[first_exceed_index, 0]\n",
        "\n",
        "        print(f\"First threshold exceedance at time: {first_exceed_time:.2e} seconds\")\n",
        "\n",
        "        # Now get the stable state after 40ns\n",
        "        mask = time_col.iloc[:, 0] > 40e-9\n",
        "        first_stable_index = mask.idxmax()\n",
        "        first_stable_voltages = voltage_cols.iloc[first_stable_index, :]\n",
        "\n",
        "        # Convert voltages to spins\n",
        "        spins = first_stable_voltages.apply(lambda v: 1 if v > 0.55 else -1).tolist()\n",
        "\n",
        "        # Calculate Hamiltonian\n",
        "        hamiltonian_value = -sum(spins[i] * spins[j] for (i, j) in edges)\n",
        "\n",
        "        return hamiltonian_value, first_exceed_time\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in compute_hamiltonian: {str(e)}\")\n",
        "        return None, None\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leA66KBopeLA"
      },
      "source": [
        "# 5) Main Simulation Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hEgdjwS3L2N"
      },
      "outputs": [],
      "source": [
        "def run_parameter_sweep(graph='fc'):\n",
        "    # min_cap = 1.0\n",
        "    # max_cap = 100.0\n",
        "    # initial_step = 4.0\n",
        "    # step_growth = 1.2\n",
        "\n",
        "    num_tests = 50\n",
        "    max_consecutive_failures = 20\n",
        "    # capacitance_values = []\n",
        "    # current_step = initial_step\n",
        "    # current_cap = min_cap\n",
        "\n",
        "    # while current_cap <= max_cap:\n",
        "    #     capacitance_values.append(current_cap)\n",
        "    #     current_cap += current_step\n",
        "    #     current_step *= step_growth\n",
        "    #     print(f\"Cap Stored: {current_cap}\")\n",
        "\n",
        "    capacitance_values = [1,5,10,20,50,100,200]\n",
        "\n",
        "    capacitance_values = np.array(capacitance_values)\n",
        "    node_sizes = list(range(3, 17))\n",
        "    sparsity_values = np.arange(0.1, 1.1, 0.1)\n",
        "\n",
        "    results = np.full((len(node_sizes), len(sparsity_values), len(capacitance_values)), np.nan)\n",
        "    convergence_times = np.full((len(node_sizes), len(sparsity_values), len(capacitance_values)), np.nan)\n",
        "    stats = {\n",
        "        'total_attempts': np.zeros((len(node_sizes), len(sparsity_values))),\n",
        "        'consecutive_failures': np.zeros((len(node_sizes), len(sparsity_values))),\n",
        "        'valid_tests': np.zeros((len(node_sizes), len(sparsity_values)))\n",
        "    }\n",
        "\n",
        "    print(\"Pre-generating test cases...\")\n",
        "    test_cases = {}\n",
        "    for node_idx, num_nodes in enumerate(node_sizes):\n",
        "        test_cases[num_nodes] = {}\n",
        "        skip_node = False\n",
        "        for sparsity_idx, sparsity in enumerate(sparsity_values):\n",
        "            if skip_node:\n",
        "                print(f\"Skipping Nodes={num_nodes}, Sparsity={sparsity:.1f} due to earlier embedding failure\")\n",
        "                test_cases[num_nodes][sparsity] = None\n",
        "                continue\n",
        "\n",
        "            embeddings = []\n",
        "            consecutive_failures = 0\n",
        "            successful_tests = 0\n",
        "            attempts = 0\n",
        "\n",
        "            print(f\"\\nStarting embeddings for Nodes={num_nodes}, Sparsity={sparsity:.1f}\")\n",
        "\n",
        "            while successful_tests < num_tests:\n",
        "                attempts += 1\n",
        "                print(f\"Generating graph: Attempt {attempts}, Successes so far {successful_tests}/{num_tests}\")\n",
        "                G = nx.erdos_renyi_graph(num_nodes, sparsity)\n",
        "                if len(G.edges()) == 0:\n",
        "                    print(\"Graph has no edges — skipping embedding\")\n",
        "                    continue\n",
        "\n",
        "                size, square, embedding = find_minimum_lattice_size(G)\n",
        "                if embedding is None:\n",
        "                    consecutive_failures += 1\n",
        "                    print(f\"Embedding failed ({consecutive_failures} consecutive failures)\")\n",
        "                    if consecutive_failures >= max_consecutive_failures:\n",
        "                        print(f\"Too many consecutive failures for Nodes={num_nodes}, Sparsity={sparsity:.1f}. Aborting this and remaining sparsities.\")\n",
        "                        skip_node = True\n",
        "                        break\n",
        "                else:\n",
        "                    consecutive_failures = 0\n",
        "                    embeddings.append((G, embedding))\n",
        "                    successful_tests += 1\n",
        "                    print(f\"Embedding succeeded (Success count: {successful_tests}/{num_tests})\")\n",
        "\n",
        "            if skip_node:\n",
        "                for s in sparsity_values[sparsity_idx:]:\n",
        "                    print(f\"Setting remaining sparsity {s:.1f} for Nodes={num_nodes} as N/A\")\n",
        "                    test_cases[num_nodes][s] = None\n",
        "                break\n",
        "            else:\n",
        "                print(f\"Completed {successful_tests} successful embeddings for Nodes={num_nodes}, Sparsity={sparsity:.1f}\")\n",
        "                test_cases[num_nodes][sparsity] = embeddings\n",
        "\n",
        "    print(\"\\nStarting parameter sweep...\")\n",
        "    for cap_idx, cap in enumerate(tqdm(capacitance_values, desc=\"Capacitance Sweep\")):\n",
        "        global cap_values_femto\n",
        "        cap_values_femto = cap\n",
        "\n",
        "        for node_idx, num_nodes in enumerate(node_sizes):\n",
        "            for sparsity_idx, sparsity in enumerate(sparsity_values):\n",
        "                embeddings = test_cases[num_nodes][sparsity]\n",
        "                if embeddings is None:\n",
        "                    print(f\"Skipping simulation for Nodes={num_nodes}, Sparsity={sparsity:.1f} (pre-embedding failed)\")\n",
        "                    continue\n",
        "\n",
        "                successes = 0\n",
        "                valid_tests = 0\n",
        "                total_attempts = 0\n",
        "                consecutive_failures = 0\n",
        "                time_sum = 0.0\n",
        "                time_count = 0\n",
        "\n",
        "                for test_idx, (G, embedding) in enumerate(embeddings):\n",
        "                    total_attempts += 1\n",
        "                    print(f\"Testing: Nodes={num_nodes}, Sparsity={sparsity:.1f}, Cap={cap:.1f}fF, Test={test_idx+1}/{len(embeddings)}\")\n",
        "\n",
        "                    if embedding is None:\n",
        "                        print(\"Empty graph or no embedding — counting as success\")\n",
        "                        valid_tests += 1\n",
        "                        successes += 1\n",
        "                        consecutive_failures = 0\n",
        "                        continue\n",
        "\n",
        "                    with open(f\"Automated{graph}Ising.cir\", \"w\") as f:\n",
        "                        f.write(generate_spice_netlist(G, embedding, graph))\n",
        "\n",
        "                    if not run_ngspice_colab(f\"Automated{graph}Ising.cir\"):\n",
        "                        consecutive_failures += 1\n",
        "                        print(\"SPICE simulation failed\")\n",
        "                        if consecutive_failures >= max_consecutive_failures:\n",
        "                            print(f\"Reached max consecutive failures ({max_consecutive_failures})\")\n",
        "                            break\n",
        "                        continue\n",
        "\n",
        "                    print(\"SPICE simulation successful\")\n",
        "\n",
        "                    H_bm = solve_ising_problem(G)\n",
        "                    H, time = compute_hamiltonian(f\"Automated{graph}Ising.csv\", G.edges())\n",
        "                    print(f\"Computed H: {H}, Baseline H: {H_bm}\")\n",
        "\n",
        "                    if H is None:\n",
        "                        consecutive_failures += 1\n",
        "                        print(\"Hamiltonian computation failed\")\n",
        "                        continue\n",
        "\n",
        "                    valid_tests += 1\n",
        "                    consecutive_failures = 0\n",
        "\n",
        "                    if time is not None and time > 0:\n",
        "                        time_sum += float(time)\n",
        "                        time_count += 1\n",
        "\n",
        "                    if H == H_bm:\n",
        "                        successes += 1\n",
        "                        print(\"Solution matches baseline!\")\n",
        "                    else:\n",
        "                        print(\"Solution does not match baseline\")\n",
        "\n",
        "                clear_output()\n",
        "                if valid_tests > 0:\n",
        "                    results[node_idx, sparsity_idx, cap_idx] = successes / valid_tests\n",
        "                    if time_count > 0:\n",
        "                        convergence_times[node_idx, sparsity_idx, cap_idx] = time_sum / time_count\n",
        "\n",
        "                print(f\"\\nCompleted: Nodes={num_nodes}, Sparsity={sparsity:.1f}, Cap={cap:.1f}fF\")\n",
        "                print(f\"Results: {successes}/{valid_tests} successes\")\n",
        "                print(f\"Convergence time: {convergence_times[node_idx, sparsity_idx, cap_idx] if time_count > 0 else 'N/A'}\")\n",
        "\n",
        "                stats['total_attempts'][node_idx, sparsity_idx] = total_attempts\n",
        "                stats['consecutive_failures'][node_idx, sparsity_idx] = consecutive_failures\n",
        "                stats['valid_tests'][node_idx, sparsity_idx] = valid_tests\n",
        "\n",
        "    return {\n",
        "        'success_rates': results,\n",
        "        'convergence_times': convergence_times,\n",
        "        'capacitance_values': capacitance_values,\n",
        "        'node_sizes': node_sizes,\n",
        "        'sparsity_values': sparsity_values,\n",
        "        'stats': stats\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsAj2ooVpmXd"
      },
      "source": [
        "# 6) Plotting Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2V0mbX_C3QpA"
      },
      "outputs": [],
      "source": [
        "def plot_optimal_capacitance(results, capacitance_values, node_sizes, sparsity_values):\n",
        "    # Find the best capacitance for each (node, sparsity) pair\n",
        "    best_cap_indices = np.argmax(results, axis=2)\n",
        "    capacitance_values = np.round(capacitance_values, 2)\n",
        "    best_success_rates = np.max(results, axis=2)\n",
        "\n",
        "    # Create annotations - show capacitance value or N/A\n",
        "    annotations = np.empty_like(best_cap_indices, dtype=object)\n",
        "    for i in range(best_cap_indices.shape[0]):\n",
        "        for j in range(best_cap_indices.shape[1]):\n",
        "            if best_success_rates[i,j] > 0:\n",
        "                annotations[i,j] = f\"{capacitance_values[best_cap_indices[i,j]]}fF\\n({best_success_rates[i,j]:.2f})\"\n",
        "            else:\n",
        "                annotations[i,j] = \"N/A\"\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.heatmap(\n",
        "        best_success_rates,\n",
        "        xticklabels=[f\"{s:.1f}\" for s in sparsity_values],\n",
        "        yticklabels=node_sizes,\n",
        "        annot=annotations,\n",
        "        fmt=\"\",\n",
        "        cmap=\"YlGnBu\",\n",
        "        vmin=0,\n",
        "        vmax=1,\n",
        "        linewidths=0.5,\n",
        "        linecolor='gray'\n",
        "    )\n",
        "    plt.title(\"Optimal Capacitance Values and Success Rates\")\n",
        "    plt.xlabel(\"Graph Sparsity\")\n",
        "    plt.ylabel(\"Number of Nodes\")\n",
        "\n",
        "    # Create custom legend\n",
        "    from matplotlib.patches import Patch\n",
        "    legend_elements = [Patch(facecolor='lightgray', edgecolor='black', label='N/A: No successful cases')]\n",
        "    plt.legend(handles=legend_elements, loc='upper right')\n",
        "    plt.show()\n",
        "    # plt.savefig(\"heatmap_plots/optimal_capacitance.png\", bbox_inches='tight', dpi=300)\n",
        "    # plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5himaqRhOmwk"
      },
      "outputs": [],
      "source": [
        "def plot_convergence_times(convergence_times, capacitance_values, node_sizes, sparsity_values):\n",
        "    \"\"\"Plot heatmaps of convergence times for each node size.\"\"\"\n",
        "    for i, num_nodes in enumerate(node_sizes):\n",
        "        plt.figure(figsize=(10, 6))\n",
        "\n",
        "        # Create a 2D array of convergence times for this node size\n",
        "        times_2d = np.nanmean(convergence_times[i], axis=1)  # Average across sparsity values\n",
        "\n",
        "        # Create the heatmap\n",
        "        sns.heatmap(times_2d.T,\n",
        "                    xticklabels=[f\"{s:.1f}\" for s in sparsity_values],\n",
        "                    yticklabels=[f\"{c:.1f}\" for c in capacitance_values],\n",
        "                    cmap=\"viridis\",\n",
        "                    annot=True, fmt=\".1f\",\n",
        "                    cbar_kws={'label': 'Convergence Time (s)'})\n",
        "\n",
        "        plt.title(f\"Average Convergence Times for {num_nodes} Nodes\")\n",
        "        plt.xlabel(\"Sparsity\")\n",
        "        plt.ylabel(\"Capacitance (fF)\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f\"convergence_times_{num_nodes}_nodes.png\")\n",
        "        plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB1PLolgp0G8"
      },
      "source": [
        "# 7) MAIN (Takes the most time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Se3XLEJF3Tsx",
        "outputId": "b5daee9d-f4f3-421b-d6fe-0d929261635d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Capacitance Sweep: 100%|██████████| 7/7 [2:04:56<00:00, 1070.87s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Completed: Nodes=16, Sparsity=0.2, Cap=200.0fF\n",
            "Results: 13/50 successes\n",
            "Convergence time: 1.8297799999999995e-08\n",
            "Skipping simulation for Nodes=16, Sparsity=0.3 (pre-embedding failed)\n",
            "Skipping simulation for Nodes=16, Sparsity=0.4 (pre-embedding failed)\n",
            "Skipping simulation for Nodes=16, Sparsity=0.5 (pre-embedding failed)\n",
            "Skipping simulation for Nodes=16, Sparsity=0.6 (pre-embedding failed)\n",
            "Skipping simulation for Nodes=16, Sparsity=0.7 (pre-embedding failed)\n",
            "Skipping simulation for Nodes=16, Sparsity=0.8 (pre-embedding failed)\n",
            "Skipping simulation for Nodes=16, Sparsity=0.9 (pre-embedding failed)\n",
            "Skipping simulation for Nodes=16, Sparsity=1.0 (pre-embedding failed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "results_fc = run_parameter_sweep(graph=\"fc\")\n",
        "results_lattice = run_parameter_sweep(graph=\"lattice\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lIhlbYz3X8a"
      },
      "outputs": [],
      "source": [
        "# results_df.to_csv(\"ising_simulation_results.csv\", index=False)\n",
        "# files.download(\"ising_simulation_results.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bh67DLxU3cmm"
      },
      "outputs": [],
      "source": [
        "# Generate plots\n",
        "plot_optimal_capacitance(results_fc['success_rates'],\n",
        "                        results_fc['capacitance_values'],\n",
        "                        results_fc['node_sizes'],\n",
        "                        results_fc['sparsity_values'])\n",
        "\n",
        "plot_optimal_capacitance(results_lattice['success_rates'],\n",
        "                        results_lattice['capacitance_values'],\n",
        "                        results_lattice['node_sizes'],\n",
        "                        results_lattice['sparsity_values'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "lxjnsCs9ot-Y",
        "QKllj5Dlo4Oi",
        "HuWPbO-zpBnD",
        "d2KbtUJApNbn",
        "NsAj2ooVpmXd"
      ],
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNkK26FJWj26vx2nl36/vp1",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}